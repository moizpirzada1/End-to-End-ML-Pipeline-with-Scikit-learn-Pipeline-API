{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c61cdb4-b845-4e86-aaa5-b28c11630948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "# Correct file paths\n",
    "MODEL_PATH = \"models/churn_pipeline.pkl\"\n",
    "SCHEMA_PATH = \"models/schema.json\"  # Update if stored elsewhere\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model_and_schema():\n",
    "    # Try loading model\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        st.error(f\"Model file not found: {MODEL_PATH}\")\n",
    "        st.stop()\n",
    "    try:\n",
    "        model = joblib.load(MODEL_PATH)\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading model: {e}\")\n",
    "        st.stop()\n",
    "\n",
    "    # Try loading schema\n",
    "    if os.path.exists(SCHEMA_PATH):\n",
    "        try:\n",
    "            with open(SCHEMA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                schema = json.load(f)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error loading schema: {e}\")\n",
    "            st.stop()\n",
    "    else:\n",
    "        # Auto-generate schema from model feature names if available\n",
    "        if hasattr(model, \"feature_names_in_\"):\n",
    "            schema = {\n",
    "                \"features\": [\n",
    "                    {\"name\": feat, \"type\": \"number\", \"default\": 0}\n",
    "                    for feat in model.feature_names_in_\n",
    "                ]\n",
    "            }\n",
    "            st.warning(\"Schema file not found. Generated default schema from model features.\")\n",
    "        else:\n",
    "            st.error(\"Schema file not found and model has no feature name metadata.\")\n",
    "            st.stop()\n",
    "\n",
    "    return model, schema\n",
    "\n",
    "# Single input form\n",
    "def single_input_form(schema):\n",
    "    st.subheader(\"Single Prediction Input\")\n",
    "    input_data = {}\n",
    "    for feat in schema[\"features\"]:\n",
    "        name = feat[\"name\"]\n",
    "        ftype = feat[\"type\"]\n",
    "        default_val = feat.get(\"default\", 0 if ftype in [\"number\", \"integer\"] else \"\")\n",
    "\n",
    "        if ftype == \"number\":\n",
    "            input_data[name] = st.number_input(name, value=float(default_val))\n",
    "        elif ftype == \"integer\":\n",
    "            input_data[name] = st.number_input(name, value=int(default_val), step=1)\n",
    "        else:\n",
    "            input_data[name] = st.text_input(name, value=str(default_val))\n",
    "    return input_data\n",
    "\n",
    "# Prediction functions\n",
    "def predict_single(model, row):\n",
    "    df = pd.DataFrame([row])\n",
    "    return model.predict(df)[0]\n",
    "\n",
    "def predict_batch(model, df):\n",
    "    preds = model.predict(df)\n",
    "    df[\"prediction\"] = preds\n",
    "    return df\n",
    "\n",
    "# Main app\n",
    "def main():\n",
    "    st.title(\"ML Pipeline Prediction App\")\n",
    "\n",
    "    model, schema = load_model_and_schema()\n",
    "\n",
    "    tab1, tab2 = st.tabs([\"Single Input\", \"Batch CSV Upload\"])\n",
    "\n",
    "    # Single Prediction\n",
    "    with tab1:\n",
    "        row = single_input_form(schema)\n",
    "        if st.button(\"Predict Single\"):\n",
    "            try:\n",
    "                result = predict_single(model, row)\n",
    "                st.success(f\"Prediction: {result}\")\n",
    "            except Exception as e:\n",
    "                st.error(f\"Prediction failed: {e}\")\n",
    "\n",
    "    # Batch Prediction\n",
    "    with tab2:\n",
    "        st.subheader(\"Upload CSV for Batch Predictions\")\n",
    "        st.caption(f\"Required columns: {[f['name'] for f in schema['features']]}\")\n",
    "        uploaded_file = st.file_uploader(\"Choose CSV file\", type=\"csv\")\n",
    "\n",
    "        if uploaded_file is not None:\n",
    "            try:\n",
    "                df = pd.read_csv(uploaded_file)\n",
    "                missing_cols = [f['name'] for f in schema['features'] if f['name'] not in df.columns]\n",
    "\n",
    "                if missing_cols:\n",
    "                    st.error(f\"Missing columns: {missing_cols}\")\n",
    "                else:\n",
    "                    result_df = predict_batch(model, df)\n",
    "                    st.dataframe(result_df)\n",
    "\n",
    "                    csv_buf = StringIO()\n",
    "                    result_df.to_csv(csv_buf, index=False)\n",
    "                    st.download_button(\n",
    "                        \"Download Predictions\",\n",
    "                        data=csv_buf.getvalue(),\n",
    "                        file_name=\"predictions.csv\",\n",
    "                        mime=\"text/csv\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                st.error(f\"Batch prediction failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shopgenie)",
   "language": "python",
   "name": "shopgenie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
